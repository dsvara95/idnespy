import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re
import time
import random
from urllib.parse import quote_plus
from pathlib import Path
import argparse
import json

# ==== PARSOV√ÅN√ç ARGUMENTU --jmeno ====
parser = argparse.ArgumentParser(description="Skript pro hled√°n√≠ soutƒõ≈æ√≠ na Lidovky.cz")
parser.add_argument("--jmeno", required=True, help="Zadej jm√©no, nap≈ô. 'david' nebo 'hanka'")
args = parser.parse_args()

JMENO = args.jmeno.lower()
JMENO_HLEDANI = JMENO.capitalize()
COOKIES_FILE = f"cookies_{JMENO}.json"
NAVSTIVENE_SOUBOR = f"navstivene_lidovky_{JMENO}.txt"
LOG_SOUBOR = f"soutez_log_{JMENO}.txt"

# ==== NASTAVEN√ç ====
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0"
}
SOUTEZNI_REGEX = re.compile(r"https://www\.idnes\.cz/ekonomika/megahra-o-auto[^\"]+")

# ==== FUNKCE ====
def load_cookies(filename):
    with open(filename, "r", encoding="utf-8") as f:
        raw = json.load(f)
    return {cookie["name"]: cookie["value"] for cookie in raw}

def log_udalost(text):
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    line = f"{now}: {text}"
    print(line)
    with open(LOG_SOUBOR, "a", encoding="utf-8") as f:
        f.write(line + "\n")

def nacti_navstivene():
    path = Path(NAVSTIVENE_SOUBOR)
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            return set(line.strip() for line in f.readlines())
    return set()

def uloz_navstiveny(odkaz):
    with open(NAVSTIVENE_SOUBOR, "a", encoding="utf-8") as f:
        f.write(odkaz + "\n")

def je_prihlaseny(cookies):
    try:
        r = requests.get("https://www.idnes.cz/ucet", cookies=cookies, headers=HEADERS)
        return JMENO_HLEDANI in r.text
    except:
        return False

def ziskej_odkazy_z_archivu(datum, stranka=1):
    url = f"https://www.lidovky.cz/data.aspx?type=infinitesph&r=sph&section=lidovky&strana={stranka}&version=sph2024"
    r = requests.get(url, cookies=cookies, headers=HEADERS)
    log_udalost(f"üìÑ Z√≠sk√°v√°m ƒçl√°nky z: {url}")
    soup = BeautifulSoup(r.text, "html.parser")
    odkazy = []

    for art_div in soup.select("div.art"):
        a_tag = art_div.find("a", class_="art-link")
        if a_tag and a_tag.get("href"):
            odkazy.append(a_tag["href"])

    return list(set(odkazy))

# ==== HLAVN√ç LOGIKA ====

datum_puvodni = "1. 1. 2025"
datum = quote_plus(datum_puvodni)

cookies = load_cookies(COOKIES_FILE)
if not je_prihlaseny(cookies):
    log_udalost("‚ùå Nejste p≈ôihl√°≈°en√Ω. Skript ukonƒçen.")
    exit()

navstivene = nacti_navstivene()
stranka = 1
while True:
    odkazy = ziskej_odkazy_z_archivu(datum, stranka)
    if not odkazy:
        log_udalost(f"‚úÖ Konec ‚Äì ≈æ√°dn√© dal≈°√≠ ƒçl√°nky na str√°nce {stranka}")
        break

    for odkaz in odkazy:
        if odkaz in navstivene:
            log_udalost(f"‚úÖ ƒål√°nek ji≈æ nav≈°t√≠ven: {odkaz}")
            continue

        log_udalost(f"üîç Kontroluji ƒçl√°nek: {odkaz}")
        try:
            html = requests.get(odkaz, cookies=cookies, headers=HEADERS, timeout=10).text
            soup = BeautifulSoup(html, "html.parser")

            # === NOVƒö: detekce publikace a aktualizace ===
            time_span = soup.find("span", class_="time-date", itemprop="datePublished")
            aktual_span = soup.find("span", class_="aktual")
            datum_aktualizace = None
            if aktual_span:
                date_modified = aktual_span.find("span", itemprop="dateModified")
                if date_modified and date_modified.get("content"):
                    datum_aktualizace = date_modified["content"].split("T")[0]
                    log_udalost(f"üìÖ Datum aktualizace ƒçl√°nku: {datum_aktualizace}")
                else:
                    log_udalost("‚ö†Ô∏è Datum aktualizace ƒçl√°nku nenalezeno.")

            if time_span and time_span.get("content"):
                datum_clanku = time_span["content"]
                log_udalost(f"üìÖ Datum ƒçl√°nku: {datum_clanku}")
            else:
                log_udalost("‚ö†Ô∏è Datum ƒçl√°nku nenalezeno.")
                datum_clanku = "9999-12-31"  # fallback

            last_date = "2025-03-20"
            if datum_clanku < last_date and (datum_aktualizace and datum_aktualizace < last_date):
                log_udalost(f"üõë ƒål√°nek je star≈°√≠ ne≈æ {last_date}. Ukonƒçuji cyklus.")
                exit()

            match = SOUTEZNI_REGEX.search(html)
            if match:
                soutez_odkaz = match.group(0)
                log_udalost(f"üéØ Nalezen soutƒõ≈æn√≠ odkaz: {soutez_odkaz}")
                try:
                    soutez_resp = requests.get(soutez_odkaz, cookies=cookies, headers=HEADERS, timeout=10)
                    log_udalost(f"üì® Odesl√°n po≈æadavek na soutƒõ≈æn√≠ odkaz ‚Äì status: {soutez_resp.status_code}")
                except Exception as e:
                    log_udalost(f"‚ùó Chyba p≈ôi odes√≠l√°n√≠ soutƒõ≈æn√≠ho odkazu: {e}")
            else:
                log_udalost("‚ùå Soutƒõ≈æn√≠ odkaz nenalezen.")
        except Exception as e:
            log_udalost(f"‚ö†Ô∏è Chyba p≈ôi naƒç√≠t√°n√≠ ƒçl√°nku: {e}")

        uloz_navstiveny(odkaz)
        time.sleep(random.randint(3, 10))

    stranka += 1
